{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime, timedelta, date\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer \n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Land Classification Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"landclass_locust.csv\")\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"date\" column needs to be parsed as a date object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=pd.DatetimeIndex(df['date'])\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of Land Cover Classification (LCC) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['lcc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data in Kenya map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya = gpd.read_file(r'kenya_shapefile/County.shp')\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    crs={'init': 'epsg:4326'},\n",
    "    geometry=[Point(xy) for xy in zip(df.long, df.lat)])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(6, 10))\n",
    "\n",
    "kenya.plot(ax=ax, facecolor=\"none\", edgecolor='black', lw=0.7)#color = 'yellow')\n",
    "gdf.plot(column = 'lcc', ax = ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Sentinel2 Band Values to Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two date columns to define the date period of the Sentinel2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_min']= df['date'] -  pd.to_timedelta(16, unit='d')\n",
    "df['date_max']= df['date'] +  pd.to_timedelta(16, unit='d')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_to_point(x):\n",
    "    bands_s2 = ['B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9']\n",
    "    lat = x['lat']\n",
    "    long = x['long']\n",
    "    p = ee.Geometry.Point([long,lat])\n",
    "    \n",
    "    #select image based on following criteria:\n",
    "    #* within the date range we defined\n",
    "    #* sort all images by cloud cover \n",
    "    #* select images containing our point of image\n",
    "    #* least cloud-covered images\n",
    "    \n",
    "    img = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "    .filterDate(x['date_min'].strftime('%Y-%m-%d'), x['date_max'].strftime('%Y-%m-%d')) \\\n",
    "    .sort('CLOUD_COVER') \\\n",
    "    .filterBounds(p) \\\n",
    "    .first()\n",
    "    try: \n",
    "        #extract value from the above image to the point of interest\n",
    "        temp = img.select(bands_s2).sampleRegions(collection=p, scale=10, geometries=True)\n",
    "        info = temp.getInfo()\n",
    "        print(\"info: \", info)\n",
    "        print(\" \")\n",
    "        values = tt['features'][0]['properties']\n",
    "        print(\"values: \", values)\n",
    "        print(\" \")\n",
    "    except:\n",
    "        values = {'B11':0, 'B12':0, 'B2':0, 'B3':0, 'B4':0, 'B5':0, 'B6':0, 'B7':0, 'B8':0, 'B8A':0, 'B9':0}\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT Run this command for the interest of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### result = df.apply(extract_to_point,axis=1,result_type='reduce')\n",
    "### s2=pd.DataFrame(result.tolist())\n",
    "### s2['lat']=df['lat']\n",
    "### s2['long']=df['long']\n",
    "### s2['date']=df['date']\n",
    "### s2['lcc']=df['lcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example showing what extract_to_point function is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df.iloc[3:5,:].apply(extract_to_point,axis=1,result_type='reduce')\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to mandatory code\n",
    "\n",
    "For the interest of time, use cached data for the s2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.read_csv(\"s2.csv\")\n",
    "display(s2.head(5))\n",
    "s2['NDVI'] = (s2['B8'] - s2['B4'])/(s2['B8'] + s2['B4'])\n",
    "s2.drop(['lat','long','date'],axis = 1, inplace = True)\n",
    "lcc_code = {'Cultivated and managed vegetation/agriculture (cropland)':0, \n",
    "            'Urban / built up':1, \n",
    "            'Open forest, unknown':2}\n",
    "s2['lcc'] = s2['lcc'].map(lcc_code)\n",
    "\n",
    "display(s2.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = s2.drop(['lcc'],axis = 1)\n",
    "y = s2['lcc']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define searching grids and other parameters in GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    tree_method=\"hist\",\n",
    "    seed=42,\n",
    "    nthread=-1,\n",
    ")\n",
    "\n",
    "\n",
    "kfold = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1234)\n",
    "\n",
    "parameters = {\n",
    "    #'eta' : [0.025, 0.5, 0.1],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'n_estimators': range(80, 100, 10),   \n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    #'min_child_weight': [1, 3, 5],\n",
    "    #'gamma': [0, 0.5, 1],\n",
    "    #'subsample': np.arange(0.6 ,0.9, 0.1),\n",
    "    #'colsample_bytree':[0.5 ,0.75 ,1.0],\n",
    "    #'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    #'eval_metric': 'mcc',\n",
    "    'eval_set': [[X_test, y_test]]\n",
    "}\n",
    "\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring=mcc_scorer,\n",
    "    cv=kfold,\n",
    "    verbose=True#,\n",
    "    #n_jobs=2 #-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best parameters found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, grid_search.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(\n",
    "    grid_search, X_test, y_test, \n",
    "    cmap=plt.cm.Blues,\n",
    "    display_labels=['cropland', 'Urban', 'forest'])\n",
    "disp.ax_.set_title(\"XGBoost Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "plt.bar(x = X_train.columns, height = grid_search.best_estimator_.feature_importances_)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: how to extract time-series Sentinel2 data to points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get a small subset of the entire dataset to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['date'],inplace=True)\n",
    "subset = df.iloc[:5,:3]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_s2 = ['B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9']\n",
    "def extract_timeseries_to_point(x):\n",
    "    lat = x['lat']\n",
    "    long = x['long']\n",
    "    p = ee.Geometry.Point([long,lat])\n",
    "    \n",
    "    #Create an image collection with 6-month's sentinel2 images, one for each month\n",
    "    d = x['date']\n",
    "    date_list = [(d + timedelta(30*i)).strftime('%Y-%m-%d') for i in range(-3,4)]\n",
    "    image_ls = []\n",
    "    for i in range(0,6):\n",
    "        s =  ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "        .filterDate(date_list[i], date_list[i+1]) \\\n",
    "        .sort('CLOUD_COVER') \\\n",
    "        .filterBounds(p).first()\n",
    "        image_ls.append(s)\n",
    "    img_col = ee.ImageCollection(image_ls)\n",
    "    \n",
    "    #Extract values from the image collection to the point of interest and save to a csv\n",
    "    def extract(img):\n",
    "        return img.select(bands_s2).sampleRegions(collection=p, scale=10, geometries=True)\n",
    "    \n",
    "    newft = ee.FeatureCollection(img_col.map(extract)).flatten()\n",
    "    f = newft.getInfo()['features']\n",
    "    keys = f[0]['properties'].keys()\n",
    "    values = zip(f[0]['properties'].values(),f[1]['properties'].values(),f[2]['properties'].values(),f[3]['properties'].values(),f[4]['properties'].values(),f[5]['properties'].values())\n",
    "    dictionary = dict(zip(keys, values))\n",
    "    \n",
    "    display(pd.DataFrame.from_dict(dictionary))\n",
    "    pd.DataFrame.from_dict(dictionary).to_csv('timeseries/df_'+str(long)+'_'+str(lat)+'_'+d.strftime('%Y%m%d')+'.csv')\n",
    "    \n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.apply(extract_timeseries_to_point,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
